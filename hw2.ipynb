{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework I - Report\n",
    "\n",
    "Cecília Correia, 106827\n",
    "<br>Patrícia Gameiro, 107245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming [9v]\n",
    "\n",
    "**Consider the diabetes.arff data available at the homework tab, comprising 8 biological\n",
    "features to classify 768 patients into 2 classes (normal, diabetes).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [1v]\n",
    "\n",
    "**ANOVA is a statistical test that can be used to assess the discriminative power of a single input variable. Using `f_classif` from `sklearn`, identify the input variables with the worst and best discriminative power. Plot their class-conditional probability density functions.**\n",
    "\n",
    "**Using sklearn, apply a stratified 70-30 training-testing split with a fixed seed\n",
    "(`random_state=1`), and assess in a single plot the training and testing accuracies of a decision tree\n",
    "with no depth limits (and remaining default behavior) for a varying number of selected features\n",
    "in `{5,10,40,100,250,700}`. Feature selection should be performed before decision tree learning\n",
    "considering the discriminative power of the input variables according to mutual information\n",
    "criterion (`mutual_info_classif`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "from sklearn import model_selection, tree, metrics\n",
    "from sklearn.feature_selection import f_classif\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the ARFF file\n",
    "data = loadarff(\"./data/diabetes.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "df[\"Outcome\"] = df[\"Outcome\"].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from the outcome \n",
    "X = df.drop(\"Outcome\", axis = 1)\n",
    "y = df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimportance = f_classif(X, y)\n",
    "\n",
    "max_f_index = fimportance[0].argmax()  \n",
    "min_f_index = fimportance[0].argmin()  \n",
    "\n",
    "print(f\"Best discriminative feature: {X.columns.values[max_f_index]} (F = {fimportance[0][max_f_index]})\")\n",
    "print(f\"Worst discriminative feature: {X.columns.values[min_f_index]} (F = {fimportance[0][min_f_index]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature = X.columns.values[max_f_index]\n",
    "worst_feature = X.columns.values[min_f_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.kdeplot(\n",
    "    data = df,\n",
    "    x = best_feature,\n",
    "    hue = \"Outcome\",\n",
    "    fill = True,\n",
    "    common_norm = False\n",
    ")\n",
    "plt.title(\"Highest discriminative power\")\n",
    "plt.xlabel(best_feature)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend((\"Normal\", \"Diabetes\"))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(\n",
    "    data = df,\n",
    "    x = worst_feature,\n",
    "    hue = \"Outcome\",\n",
    "    fill = True,\n",
    "    common_norm = False\n",
    ")\n",
    "plt.title(\"Lowest discriminative power\")\n",
    "plt.xlabel(worst_feature)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend((\"Normal\", \"Diabetes\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [4v]\n",
    "\n",
    "**Using a stratified 80-20 training-testing split with a fixed seed\n",
    "(`random_state=1`), assess in a single plot both the training and testing accuracies of a decision tree with minimum sample split in `{2, 5,10, 20, 30, 50, 100}` and the remaining parameters as default.**\n",
    "\n",
    "***[optional]* Note that split thresholding of numeric variables in decision trees is non- deterministic in sklearn, hence you may opt to average the results using 10 runs per parameterization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SAMPLES_SPLIT = [2, 5, 10, 20, 30, 50, 100] \n",
    "runs = 10  \n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "            X, y, train_size = 0.8, stratify = y, random_state = 1 \n",
    "        )\n",
    "\n",
    "average_training_accuracy = []  \n",
    "average_test_accuracy = []  \n",
    "\n",
    "for min_samples_split in MIN_SAMPLES_SPLIT:\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        predictor = tree.DecisionTreeClassifier(min_samples_split = min_samples_split, random_state = 1)\n",
    "        predictor.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = predictor.predict(X_train)\n",
    "        y_test_pred = predictor.predict(X_test)\n",
    "\n",
    "        train_acc = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = metrics.accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "    average_training_accuracy.append(np.mean(train_acc_list))\n",
    "    average_test_accuracy.append(np.mean(test_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    MIN_SAMPLES_SPLIT,\n",
    "    average_training_accuracy,  \n",
    "    label = \"Training Accuracy\",\n",
    "    marker=\"+\",\n",
    "    color=\"#4caf50\",\n",
    ")\n",
    "plt.plot(\n",
    "    MIN_SAMPLES_SPLIT,\n",
    "    average_test_accuracy,  \n",
    "    label = \"Test Accuracy\",\n",
    "    marker = \".\",\n",
    "    color = \"#ff5722\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Minimum Samples Split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [2V]\n",
    "\n",
    "**Critically analyze these results, including the generalization capacity across settings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results above, you can observe that the training accuracy decreases as the minimum samples split increases. However, the test accuracy initially improves and then plateaus, indicating that the model begins to generalize better as the minimum samples split increases. Eventually, though, the performance on the test set stabilizes while the training accuracy continues to drop, which may suggest that the model is becoming too simple and losing some capacity to learn more nuanced patterns in the data.\n",
    "\n",
    "Looking at the gap between the training and test accuracy curves, we can assess the generalization capacity. A small gap with both accuracies being relatively close to each other usually signifies good generalization. In this case, the most beneficial minimum samples split appears to be around 20-50, where the test accuracy is highest and the gap between the training and test accuracy is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [2V]\n",
    "\n",
    "**To deploy the predictor, a healthcare provider opted to learn a single decision tree (´random_state=1´) using *all* available data and ensuring that the maximum depth would be 3 in order to avoid overfitting risks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = tree.DecisionTreeClassifier( max_depth = 3, random_state = 1)\n",
    "predictor.fit(X, y)\n",
    "\n",
    "class_names = [\"Normal\", \"Diabetes\"]  \n",
    "\n",
    "figure = plt.figure(figsize = (12, 6))\n",
    "tree.plot_tree(predictor, feature_names = X.columns.values.tolist(), class_names = class_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Explain what characterizes diabetes by identifying the conditional associations together with their posterior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree reveals key conditional associations that characterize diabetes. The most important predictor is glucose level: patients with glucose levels below 127.5 are predominantly classified as \"Normal\", indicating that lower glucose levels are associated with a lower likelihood of diabetes. Conversely, when glucose exceeds 127.5, there is a significant increase in diabetes cases. For patients with high glucose, BMI becomes a crucial factor. Individuals with a BMI above 29.95 and glucose levels higher than 157.5 have a high probability of being diagnosed with diabetes, suggesting that both high BMI and glucose are strong indicators of the disease. On the other hand, lower BMI and glucose levels are associated with a higher chance of being \"Normal\". These associations help predict whether a patient is likely to have diabetes, with glucose levels serving as the primary determinant, followed by BMI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
